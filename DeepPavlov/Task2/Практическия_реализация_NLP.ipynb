{"cells":[{"cell_type":"markdown","metadata":{"id":"8MDzsh_rqrGD"},"source":["# Практическия реализация NLP"]},{"cell_type":"markdown","metadata":{"id":"d3MQ-j3-XzqM"},"source":["In this assignment you will perform sentiment analysis of the IMDBs reviews by using RNN."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"ZZ3tq2efXzqN","executionInfo":{"status":"ok","timestamp":1658128813696,"user_tz":-240,"elapsed":114830,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ac834e72-ca22-4f8d-8046-832188188180"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.6.0\n","  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n","\u001b[K     |████████████████████████████████| 748.8 MB 17 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.21.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.0+cu113\n","    Uninstalling torch-1.12.0+cu113:\n","      Successfully uninstalled torch-1.12.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 1.6.0 which is incompatible.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.6.0 which is incompatible.\n","torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.6.0 which is incompatible.\n","fastai 2.7.6 requires torch<1.13,>=1.7, but you have torch 1.6.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.7\n","  Downloading torchtext-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (4.5 MB)\n","\u001b[K     |████████████████████████████████| 4.5 MB 31.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7) (2.23.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7) (1.6.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7) (4.64.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 55.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7) (1.21.6)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7) (1.24.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.7) (0.16.0)\n","Installing collected packages: sentencepiece, torchtext\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.13.0\n","    Uninstalling torchtext-0.13.0:\n","      Successfully uninstalled torchtext-0.13.0\n","Successfully installed sentencepiece-0.1.96 torchtext-0.7.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"]}],"source":["# %%capture\n","!pip install torch==1.6.0\n","!pip install torchtext==0.7\n","!pip install numpy\n","!pip install pandas"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"bfusPGesXzqP","executionInfo":{"status":"ok","timestamp":1658128814327,"user_tz":-240,"elapsed":651,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","\n","from torchtext import datasets\n","\n","from torchtext.data import Field, LabelField\n","from torchtext.data import BucketIterator\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"]},{"cell_type":"code","source":["random_seed = 42\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.backends.cudnn.deterministic = True\n","np.random.seed(random_seed)"],"metadata":{"id":"g0YVxLw47S4Y","executionInfo":{"status":"ok","timestamp":1658128814328,"user_tz":-240,"elapsed":12,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"axvxFxD0XzqP"},"source":["### Preparing Data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"uFRWg-SDXzqQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658128814329,"user_tz":-240,"elapsed":11,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"outputId":"afb55883-de0a-45d1-8ed2-a8170b52dd3c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n","/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]}],"source":["TEXT = Field(sequential=True, lower=True)\n","LABEL = LabelField()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"-KjrlhxoXzqQ","executionInfo":{"status":"ok","timestamp":1658128857463,"user_tz":-240,"elapsed":43143,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"73eabcb5-e642-4a82-c25a-d2bc622c5ca6"},"outputs":[{"output_type":"stream","name":"stdout","text":["downloading aclImdb_v1.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:08<00:00, 9.89MB/s]\n","/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"]}],"source":["train, tst = datasets.IMDB.splits(TEXT, LABEL)\n","trn, vld = train.split()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"3kfGodmCXzqR","executionInfo":{"status":"ok","timestamp":1658128859757,"user_tz":-240,"elapsed":2325,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"156819e5-c874-4764-c6ad-edabb1b184e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 1.16 s, sys: 40.7 ms, total: 1.2 s\n","Wall time: 1.19 s\n"]}],"source":["%%time\n","TEXT.build_vocab(trn)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"nGz60xZeXzqS","executionInfo":{"status":"ok","timestamp":1658128859758,"user_tz":-240,"elapsed":23,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"outputs":[],"source":["LABEL.build_vocab(trn)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"SBZXFxWQXzqT","executionInfo":{"status":"ok","timestamp":1658128859758,"user_tz":-240,"elapsed":20,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"81894cd5-1a84-4c43-a08a-843554b218dc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('the', 225693),\n"," ('a', 111990),\n"," ('and', 111448),\n"," ('of', 101112),\n"," ('to', 93691),\n"," ('is', 73340),\n"," ('in', 63498),\n"," ('i', 49202),\n"," ('this', 48843),\n"," ('that', 46403)]"]},"metadata":{},"execution_count":8}],"source":["TEXT.vocab.freqs.most_common(10)"]},{"cell_type":"markdown","metadata":{"id":"JcpRl46sXzqT"},"source":["### Creating the Iterator"]},{"cell_type":"markdown","metadata":{"id":"o1UXNIABXzqU"},"source":["During training, we'll be using a special kind of Iterator, the **BucketIterator**. \n","\n","All the neural networks require to have inputs of the same shape and size. So the data saples should be padded to the same length before gathering them into batches:\n","\n","e.g.\n","\\[ \n","\\[3, 15, 2, 7\\],\n","\\[4, 1\\], \n","\\[5, 5, 6, 8, 1\\] \n","\\] -> \\[ \n","\\[3, 15, 2, 7, **0**\\],\n","\\[4, 1, **0**, **0**, **0**\\], \n","\\[5, 5, 6, 8, 1\\] \n","\\] \n","\n","If the sequences of one batch differ greatly in length, the padding will consume a lot of wasteful memory and time. The BucketIterator groups sequences of similar lengths together for each batch to minimize padding."]},{"cell_type":"markdown","metadata":{"id":"UQBuXYjnbIZX"},"source":["The **BucketIterator** usage:"]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"XFEFe65NKdQZ","executionInfo":{"status":"ok","timestamp":1658128859759,"user_tz":-240,"elapsed":15,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"id":"gDZcwvzXXzqU","executionInfo":{"status":"ok","timestamp":1658128859759,"user_tz":-240,"elapsed":14,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fbf417dd-d62e-4448-96a0-fc0450f15ff3"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]}],"source":["train_iter, val_iter, test_iter = BucketIterator.splits(\n","        (trn, vld, tst),\n","        batch_sizes=(64, 64, 64),\n","        sort=True,\n","        sort_key=lambda x: len(x.text),\n","        sort_within_batch=False,\n","        device=device,\n","        repeat=False\n",")"]},{"cell_type":"markdown","metadata":{"id":"eae_lu0GXzqV"},"source":["Let's take a look at the output of the BucketIterator"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"kjmCSB9aXzqV","executionInfo":{"status":"ok","timestamp":1658128862165,"user_tz":-240,"elapsed":2415,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5e63e8e0-6b12-442a-ea9e-33545c8a775d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[   10,  1314,  7971,  ...,  2658, 25305,     9],\n","        [   20,   141, 22357,  ...,  1167,     7,   378],\n","        [    7,  2306,     7,  ...,     3,     3,     2],\n","        ...,\n","        [    1,     1,     1,  ...,     3,    89,   220],\n","        [    1,     1,     1,  ...,     6,   139,   513],\n","        [    1,     1,     1,  ...,  4212,  6971,   112]], device='cuda:0')"]},"metadata":{},"execution_count":11}],"source":["batch = next(train_iter.__iter__()); batch.text"]},{"cell_type":"code","source":["batch.text.shape, batch.label.shape"],"metadata":{"id":"MOpG8EyQ505A","executionInfo":{"status":"ok","timestamp":1658128862165,"user_tz":-240,"elapsed":18,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"417ba530-adb9-43fc-f9af-22c93297c561"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([34, 64]), torch.Size([64]))"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"1hm9IPdAXzqV"},"source":["The batch contains all the fields we passed to the Dataset object that can be accessed as attributes with the corresponding names."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"-xNoF1S0XzqW","executionInfo":{"status":"ok","timestamp":1658128862166,"user_tz":-240,"elapsed":15,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5eed0b77-34dd-44b8-89f6-3531b084bb81"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['batch_size', 'dataset', 'fields', 'input_fields', 'target_fields', 'text', 'label'])"]},"metadata":{},"execution_count":13}],"source":["batch.__dict__.keys()"]},{"cell_type":"markdown","metadata":{"id":"8XJ8mmEZXzqW"},"source":["### Define the RNN-based text classification model"]},{"cell_type":"markdown","metadata":{"id":"Y3MeuXZTXzqW"},"source":["Let's start with the simple architecture. Implement the model according to the scheme below.  \n","![alt text](https://miro.medium.com/max/1396/1*v-tLYQCsni550A-hznS0mw.jpeg)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"979yo1iSXzqW","executionInfo":{"status":"ok","timestamp":1658128862167,"user_tz":-240,"elapsed":9,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"outputs":[],"source":["class RNNBaseline(nn.Module):\n","    def __init__(self, hidden_dim, emb_dim, v_size):\n","        super().__init__()\n","        self.emb = nn.Embedding(v_size, emb_dim)\n","        self.gru = nn.GRU(emb_dim, hidden_dim)\n","        self.fc = nn.Linear(hidden_dim, 1)\n","            \n","    def forward(self, seq):\n","        embedded = self.emb(seq)\n","        h_seq, h_n = self.gru(embedded)\n","        preds = self.fc(h_n).squeeze()\n","        return preds"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"ytcKa0sLXzqX","executionInfo":{"status":"ok","timestamp":1658128862711,"user_tz":-240,"elapsed":553,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c37d3345-31b2-43c4-d04b-7af1d9874275"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNNBaseline(\n","  (emb): Embedding(202243, 200)\n","  (gru): GRU(200, 300)\n","  (fc): Linear(in_features=300, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":15}],"source":["em_sz = 200\n","nh = 300\n","v_size = len(TEXT.vocab)\n","model = RNNBaseline(nh, em_sz, v_size)\n","model"]},{"cell_type":"markdown","metadata":{"id":"UvctmT6MXzqX"},"source":["*If* you're using GPU, remember to call model.cuda() to move your model to the GPU."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"BEmLspl-XzqX","executionInfo":{"status":"ok","timestamp":1658128862712,"user_tz":-240,"elapsed":13,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"af2f34c5-56f9-4d6c-e2aa-797473726bed"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNNBaseline(\n","  (emb): Embedding(202243, 200)\n","  (gru): GRU(200, 300)\n","  (fc): Linear(in_features=300, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":16}],"source":["model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"wttBF3JLXzqY"},"source":["### Training loop"]},{"cell_type":"markdown","metadata":{"id":"h4HdCt7gXzqY"},"source":["Define the optimizer and the loss function"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"QruMA8qOXzqY","executionInfo":{"status":"ok","timestamp":1658128862712,"user_tz":-240,"elapsed":10,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"outputs":[],"source":["opt = optim.Adam(model.parameters(), lr=1e-3)\n","loss_func = nn.BCEWithLogitsLoss()"]},{"cell_type":"markdown","metadata":{"id":"oiQn6YO8XzqZ"},"source":["Set the number of training epochs"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"aFRXDxatXzqZ","executionInfo":{"status":"ok","timestamp":1658128862714,"user_tz":-240,"elapsed":11,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"outputs":[],"source":["epochs = 7"]},{"cell_type":"markdown","metadata":{"id":"bWdzskyGkJLw"},"source":["Finally, run the training loop"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"j3Aip0CkXzqZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658128954446,"user_tz":-240,"elapsed":91743,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"outputId":"7416531a-e1db-47b2-d6bf-fd5c9c665501"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 0.010021622337613787, Validation Loss: 0.008939041697978973\n","Epoch: 2, Training Loss: 0.0067315522074699406, Validation Loss: 0.006625395083427429\n","Epoch: 3, Training Loss: 0.0035556193845612664, Validation Loss: 0.008398453283309936\n","Epoch: 4, Training Loss: 0.0016661620554381184, Validation Loss: 0.00956684192419052\n","Epoch: 5, Training Loss: 0.0006988262528952743, Validation Loss: 0.01388237833182017\n","Epoch: 6, Training Loss: 0.0004248282752864595, Validation Loss: 0.010509449235598246\n","Epoch: 7, Training Loss: 0.00027971251561705556, Validation Loss: 0.012061216425895692\n","CPU times: user 1min 26s, sys: 2.11 s, total: 1min 28s\n","Wall time: 1min 32s\n"]}],"source":["%%time\n","for epoch in range(1, epochs + 1):\n","    running_loss = 0.0\n","    running_corrects = 0\n","    model.train() \n","    for cnt, batch in enumerate(train_iter): \n","        x = batch.text\n","        y = batch.label.type(torch.float)  # Add float\n","        opt.zero_grad()\n","        preds = model(x)\n","        loss = loss_func(preds, y)\n","        loss.backward()\n","        opt.step()\n","        running_loss += loss.item()\n","    epoch_loss = running_loss / len(trn)\n","    \n","    val_loss = 0.0\n","    model.eval()\n","    for batch in val_iter:\n","        x = batch.text\n","        y = batch.label.type(torch.float)  # Add float\n","        preds = model(x)\n","        loss = loss_func(preds, y)\n","        val_loss += loss.item()\n","\n","    val_loss /= len(vld)\n","    print(f'Epoch: {epoch}, Training Loss: {epoch_loss}, Validation Loss: {val_loss}')"]},{"cell_type":"markdown","metadata":{"id":"D_Vw14WxXzqZ"},"source":["### Calculate performance of the trained model (10 points)"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","def print_metric(model, tst=tst, test_iter=test_iter):\n","    y_true = np.zeros(len(tst))\n","    y_pred = np.zeros(len(tst))\n","    model.eval()\n","    with torch.no_grad():\n","        for i, batch in enumerate(test_iter):\n","            x = batch.text\n","            y = batch.label\n","            y_batch_pred = torch.exp(model(x))\n","            y_true[i * 64 : (i + 1) * 64] = y.cpu().numpy()\n","            y_pred[i * 64 : (i + 1) * 64] = y_batch_pred.cpu().numpy().flatten() > 0.5\n","\n","    print(f'Accuracy: {accuracy_score(y_true, y_pred):.2f}')\n","    print(f'Precision: {precision_score(y_true, y_pred):.2f}')\n","    print(f'Recall: {recall_score(y_true, y_pred):.2f}')\n","    print(f'F1: {f1_score(y_true, y_pred):.2f}')"],"metadata":{"id":"H-eeKD2FAn8j","executionInfo":{"status":"ok","timestamp":1658128955574,"user_tz":-240,"elapsed":1135,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["print_metric(model)"],"metadata":{"id":"F6IC29C8mU1q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658128960016,"user_tz":-240,"elapsed":4455,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"outputId":"01e2ba2d-0176-4b9b-f627-fc300186da6d"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.81\n","Precision: 0.75\n","Recall: 0.91\n","F1: 0.82\n"]}]},{"cell_type":"code","source":["# Accuracy: 0.81\n","# Precision: 0.75\n","# Recall: 0.91\n","# F1: 0.82"],"metadata":{"id":"x424wFZ4Jbr3","executionInfo":{"status":"ok","timestamp":1658128960017,"user_tz":-240,"elapsed":13,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kSJlVgalXzqa"},"source":["### Experiments\n","\n","Feel free to experiment with the model to improve performance scores. You can find advices [here](https://arxiv.org/abs/1801.06146). \n","\n","Below describe, please, \n"," - your improvements and challenges you faced\n"," - provide your experiments' implementation details\n"," - explain your choice of architecture/training method/regularization techniques etc."]},{"cell_type":"markdown","source":["## 1. Experiment (slanted triangular learning rates)\n","\n","Попытка реализации из приведенной статьи метода stlr. Результат обучения модели получился, мягко говоря, слабый и все же я решил оставить свою попытку здесь.\n","\n","Предположу что дело в примечании, которое я сразу не заметил \"In other words, the number of epochs times the number of updates per epoch.\""],"metadata":{"id":"Eg0If6v3RBYl"}},{"cell_type":"code","source":["class STLR(torch.optim.lr_scheduler._LRScheduler):\n","\n","    def __init__(self, optimizer, last_epoch=-1, ratio=32, T=20, cut_frac=0.1, max_lr=0.001):\n","        self.ratio = ratio\n","        self.T = T\n","        self.cut_frac = cut_frac\n","        self.max_lr = max_lr\n","        super(STLR, self).__init__(optimizer, last_epoch)\n","\n","    def get_lr(self):\n","        self.cut = int(self.T * self.cut_frac)\n","        \n","        if self.last_epoch < self.cut:\n","            p = self.last_epoch / self.cut\n","        else:\n","            p = 1 - (self.last_epoch - self.cut) / (self.cut * (1 / self.cut_frac - 1))\n","\n","        self.optimizer.param_groups[0]['lr'] = self.max_lr * (1 + p * (self.ratio - 1)) / self.ratio\n","        return [self.optimizer.param_groups[0]['lr']]"],"metadata":{"id":"O8DXk1CT40BS","executionInfo":{"status":"ok","timestamp":1658128960017,"user_tz":-240,"elapsed":10,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","opt = optim.Adam(model.parameters(), lr=0.001)\n","loss_func = nn.BCEWithLogitsLoss()\n","stlr = STLR(optimizer=opt, last_epoch=-1, ratio=32, T=epochs, cut_frac=0.1, max_lr=0.01)"],"metadata":{"id":"dvYE-lD8wnHs","executionInfo":{"status":"ok","timestamp":1658128960018,"user_tz":-240,"elapsed":10,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["%%time\n","lr_value : list = []  # Add list lr\n","for epoch in range(1, epochs + 1):\n","    running_loss = 0.0\n","    running_corrects = 0\n","    model.train() \n","    for batch in train_iter: \n","        x = batch.text\n","        y = batch.label.type(torch.float)  # Add float\n","        opt.zero_grad()\n","        preds = model(x)\n","        loss = loss_func(preds, y)\n","        loss.backward()\n","        opt.step()\n","        running_loss += loss.item()\n","    lr_value.append(opt.param_groups[0]['lr'])  # Add counter lr\n","    stlr.step()  # STLR step\n","    epoch_loss = running_loss / len(trn)\n","    \n","    val_loss = 0.0\n","    model.eval()\n","    for batch in val_iter:\n","        x = batch.text\n","        y = batch.label.type(torch.float)  # Add float\n","        preds = model(x)\n","        loss = loss_func(preds, y)\n","        val_loss += loss.item()\n","\n","    val_loss /= len(vld)\n","    print(f'Epoch: {epoch}, Training Loss: {epoch_loss}, Validation Loss: {val_loss}')"],"metadata":{"id":"GiwLzDbBSRoS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658129085624,"user_tz":-240,"elapsed":125616,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"outputId":"1e1afbae-af35-480d-a7b5-5ff9ad13f257"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 4.755150257551577e-05, Validation Loss: 0.018475054144859313\n","Epoch: 2, Training Loss: nan, Validation Loss: nan\n","Epoch: 3, Training Loss: nan, Validation Loss: nan\n","Epoch: 4, Training Loss: nan, Validation Loss: nan\n","Epoch: 5, Training Loss: nan, Validation Loss: nan\n","Epoch: 6, Training Loss: nan, Validation Loss: nan\n","Epoch: 7, Training Loss: nan, Validation Loss: nan\n","Epoch: 8, Training Loss: nan, Validation Loss: nan\n","Epoch: 9, Training Loss: nan, Validation Loss: nan\n","Epoch: 10, Training Loss: nan, Validation Loss: nan\n","CPU times: user 2min 2s, sys: 2.74 s, total: 2min 4s\n","Wall time: 2min 5s\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(range(len(lr_value)), lr_value)\n","plt.title('Form STLR ' )\n","plt.xlabel('# of iterations')\n","plt.ylabel('Learning rate')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"BufJ3MMpF-WN","executionInfo":{"status":"ok","timestamp":1658129085625,"user_tz":-240,"elapsed":26,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"outputId":"f9cec716-304c-4275-ef56-0d0b79e666df"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["print_metric(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bmmXv2OgHL8-","executionInfo":{"status":"ok","timestamp":1658129089855,"user_tz":-240,"elapsed":4248,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"outputId":"adbe359f-79fd-463d-8bee-162a6b986f0d"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.50\n","Precision: 0.00\n","Recall: 0.00\n","F1: 0.00\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["# Accuracy: 0.50\n","# Precision: 0.00\n","# Recall: 0.00\n","# F1: 0.00"],"metadata":{"id":"BJz3MI00QE04"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Experiment (3-layer LSTM)\n","В статье говорится\n","\"The same 3-layer LSTM architecture—\n","with the same hyperparameters and no additions\n","other than tuned dropout hyperparameters—\n","outperforms highly engineered models and transfer learning approaches on six widely studied text\n","classification tasks.\"\n","\n","Попробуем \"прикрутить\" 3 слоя LSTM вместо GRU и добавим Dropout 40% на каждый слой\n","\n"],"metadata":{"id":"0SUm_P5ZLb9i"}},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"status":"ok","timestamp":1658129089857,"user_tz":-240,"elapsed":7,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"id":"ZzdmFWX2MuZP"},"outputs":[],"source":["class LSTM_RNNBaseline(nn.Module):\n","    \"\"\"\n","    Helped me:\n","    https://towardsdatascience.com/implementation-differences-in-lstm-layers-tensorflow-vs-pytorch-77a31d742f74\n","    https://galhever.medium.com/sentiment-analysis-with-pytorch-part-4-lstm-bilstm-model-84447f6c4525\n","    \"\"\"\n","    def __init__(self, hidden_dim, emb_dim, v_size):\n","        super().__init__()\n","        self.emb = nn.Embedding(v_size, emb_dim)\n","        self.lstm1 = nn.LSTM(input_size=emb_dim, hidden_size=hidden_dim, dropout=0.4)\n","        self.lstm2 = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, dropout=0.4)\n","        self.lstm3 = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, dropout=0.4)\n","        self.fc = nn.Linear(hidden_dim, 1)\n","\n","    def forward(self, seq):\n","        embedded = self.emb(seq)\n","        h1, (h1_T,c1_T) = self.lstm1(embedded)\n","        h2, (h2_T, c2_T) = self.lstm2(h1)\n","        h3, (h3_T, c3_T) = self.lstm3(h2)\n","        preds = self.fc(h3[-1,:,:])  # (L,N,D∗Hout) when batch_first=False\n","        \n","        return preds.squeeze()"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"status":"ok","timestamp":1658129090526,"user_tz":-240,"elapsed":675,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"66d6be27-839b-481d-8a70-8035cded5f63","id":"57K8a_N2MuZR"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"output_type":"execute_result","data":{"text/plain":["LSTM_RNNBaseline(\n","  (emb): Embedding(202243, 200)\n","  (lstm1): LSTM(200, 300, dropout=0.4)\n","  (lstm2): LSTM(300, 300, dropout=0.4)\n","  (lstm3): LSTM(300, 300, dropout=0.4)\n","  (fc): Linear(in_features=300, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":29}],"source":["em_sz = 200\n","nh = 300\n","v_size = len(TEXT.vocab)\n","model = LSTM_RNNBaseline(nh, em_sz, v_size)\n","model"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"status":"ok","timestamp":1658129090526,"user_tz":-240,"elapsed":9,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"id":"Z74ifqb8MuZW"},"outputs":[],"source":["model.to(device)\n","opt = optim.Adam(model.parameters(), lr=1e-3)\n","loss_func = nn.BCEWithLogitsLoss()\n","epochs = 7"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658129325758,"user_tz":-240,"elapsed":235240,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"outputId":"d51daa62-8a54-4116-b8cf-d6d587d60843","id":"2eZjMXSEMuZZ"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 0.010192813185283115, Validation Loss: 0.011007394361495972\n","Epoch: 2, Training Loss: 0.010789148558889117, Validation Loss: 0.011008347916603088\n","Epoch: 3, Training Loss: 0.010822276765959604, Validation Loss: 0.01099231420358022\n","Epoch: 4, Training Loss: 0.010509782835415432, Validation Loss: 0.009640979878107707\n","Epoch: 5, Training Loss: 0.008033236139161246, Validation Loss: 0.008542178773880004\n","Epoch: 6, Training Loss: 0.004405189408149038, Validation Loss: 0.006967604927221934\n","Epoch: 7, Training Loss: 0.0019732903368771077, Validation Loss: 0.009090139547983805\n","CPU times: user 3min 30s, sys: 25.1 s, total: 3min 55s\n","Wall time: 3min 55s\n"]}],"source":["%%time\n","for epoch in range(1, epochs + 1):\n","    running_loss = 0.0\n","    running_corrects = 0\n","    model.train() \n","    for cnt, batch in enumerate(train_iter): \n","        x = batch.text\n","        y = batch.label.type(torch.float)\n","        opt.zero_grad()\n","        preds = model(x)\n","        loss = loss_func(preds, y)\n","        loss.backward()\n","        opt.step()\n","        running_loss += loss.item()\n","    epoch_loss = running_loss / len(trn)\n","    \n","    val_loss = 0.0\n","    model.eval()\n","    for batch in val_iter:\n","        x = batch.text\n","        y = batch.label.type(torch.float)\n","        preds = model(x)\n","        loss = loss_func(preds, y)\n","        val_loss += loss.item()\n","\n","    val_loss /= len(vld)\n","    print(f'Epoch: {epoch}, Training Loss: {epoch_loss}, Validation Loss: {val_loss}')"]},{"cell_type":"code","source":["print_metric(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVG0R1fGdqOJ","executionInfo":{"status":"ok","timestamp":1658129340564,"user_tz":-240,"elapsed":14812,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"outputId":"34173a1d-8a82-4375-fad2-8d15aa94e03f"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.83\n","Precision: 0.88\n","Recall: 0.76\n","F1: 0.81\n"]}]},{"cell_type":"code","source":["# Accuracy: 0.83\n","# Precision: 0.88\n","# Recall: 0.76\n","# F1: 0.81"],"metadata":{"id":"u3HfjOkQoS8L","executionInfo":{"status":"ok","timestamp":1658129340566,"user_tz":-240,"elapsed":28,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["## 3. Experiment (add BiLSTM)\n","\n","В статье упоминаются Bidirectional language model\n","\n","Посмотрим как поведет себя двунаправленная модель LSTM. За основу возьмем 3х слойную архитектуру использованную ранее."],"metadata":{"id":"NA2ReAaIPzWx"}},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"status":"ok","timestamp":1658130366327,"user_tz":-240,"elapsed":513,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"id":"6KUJPnYaPzuv"},"outputs":[],"source":["class Bi_LSTM_RNNBaseline(nn.Module):\n","    def __init__(self, hidden_dim, emb_dim, v_size):\n","        super().__init__()\n","        self.emb = nn.Embedding(v_size, emb_dim)\n","        self.lstm1 = nn.LSTM(input_size=emb_dim, hidden_size=hidden_dim, bidirectional=True, dropout=0.4)\n","        self.lstm2 = nn.LSTM(input_size=hidden_dim * 2, hidden_size=hidden_dim, bidirectional=True, dropout=0.4)\n","        self.lstm3 = nn.LSTM(input_size=hidden_dim * 2, hidden_size=hidden_dim, bidirectional=True, dropout=0.4)\n","        self.fc = nn.Linear(hidden_dim * 2, 1)\n","\n","    def forward(self, seq):\n","        embedded = self.emb(seq)\n","        h1, (h1_T,c1_T) = self.lstm1(embedded)\n","        h2, (h2_T, c2_T) = self.lstm2(h1)\n","        h3, (h3_T, c3_T) = self.lstm3(h2)\n","\n","        preds = self.fc(h3[-1,:,:])\n","        \n","        return preds.squeeze()"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"status":"ok","timestamp":1658130369292,"user_tz":-240,"elapsed":522,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e50e9add-9581-4532-d2c2-e4d567c1e129","id":"vjMToikPPzuw"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"output_type":"execute_result","data":{"text/plain":["Bi_LSTM_RNNBaseline(\n","  (emb): Embedding(202243, 200)\n","  (lstm1): LSTM(200, 300, dropout=0.4, bidirectional=True)\n","  (lstm2): LSTM(600, 300, dropout=0.4, bidirectional=True)\n","  (lstm3): LSTM(600, 300, dropout=0.4, bidirectional=True)\n","  (fc): Linear(in_features=600, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":46}],"source":["em_sz = 200\n","nh = 300\n","v_size = len(TEXT.vocab)\n","model = Bi_LSTM_RNNBaseline(nh, em_sz, v_size)\n","model"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"status":"ok","timestamp":1658130372259,"user_tz":-240,"elapsed":6,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"id":"W_sOzmzNPzux"},"outputs":[],"source":["model.to(device)\n","opt = optim.Adam(model.parameters(), lr=1e-3)\n","loss_func = nn.BCEWithLogitsLoss()\n","epochs = 7"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab3342ba-f74a-4b4a-9afc-f3d4a35aed19","id":"HBg7DVQBPzuy","executionInfo":{"status":"ok","timestamp":1658130873519,"user_tz":-240,"elapsed":499496,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 0.01012602105140686, Validation Loss: 0.009876618282000224\n","Epoch: 2, Training Loss: 0.007506006842000144, Validation Loss: 0.007359970955053965\n","Epoch: 3, Training Loss: 0.004695729856831687, Validation Loss: 0.006657442762454351\n","Epoch: 4, Training Loss: 0.0029052818368588175, Validation Loss: 0.007377871958414713\n","Epoch: 5, Training Loss: 0.0018364197396274124, Validation Loss: 0.007418536039193471\n","Epoch: 6, Training Loss: 0.0012673374699162586, Validation Loss: 0.007652659524480502\n","Epoch: 7, Training Loss: 0.0005163283224018024, Validation Loss: 0.009892187837759654\n","CPU times: user 6min 58s, sys: 1min 20s, total: 8min 18s\n","Wall time: 8min 19s\n"]}],"source":["%%time\n","for epoch in range(1, epochs + 1):\n","    running_loss = 0.0\n","    running_corrects = 0\n","    model.train() \n","    for cnt, batch in enumerate(train_iter): \n","        x = batch.text\n","        y = batch.label.type(torch.float)\n","        opt.zero_grad()\n","        preds = model(x)\n","        loss = loss_func(preds, y)\n","        loss.backward()\n","        opt.step()\n","        running_loss += loss.item()\n","    epoch_loss = running_loss / len(trn)\n","    \n","    val_loss = 0.0\n","    model.eval()\n","    for batch in val_iter:\n","        x = batch.text\n","        y = batch.label.type(torch.float)\n","        preds = model(x)\n","        loss = loss_func(preds, y)\n","        val_loss += loss.item()\n","\n","    val_loss /= len(vld)\n","    print(f'Epoch: {epoch}, Training Loss: {epoch_loss}, Validation Loss: {val_loss}')"]},{"cell_type":"code","source":["print_metric(model)"],"metadata":{"id":"z96TMmDvK0Ub","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658130903692,"user_tz":-240,"elapsed":28573,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"outputId":"e360ec2c-865d-4d6c-9d36-4e7bcc98473f"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.83\n","Precision: 0.89\n","Recall: 0.76\n","F1: 0.82\n"]}]},{"cell_type":"code","source":["# Accuracy: 0.83\n","# Precision: 0.89\n","# Recall: 0.76\n","# F1: 0.82"],"metadata":{"id":"l_pUwBdwQO4b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Experiment (add linear layer)\n","\n","Добавим один полносвязный слой в конце.\n","\n","Этот эксперимент показал лучший результат F1, и высокие результаты Recall и Precision, на тесте."],"metadata":{"id":"UK8m48SXocN2"}},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"status":"ok","timestamp":1658129868694,"user_tz":-240,"elapsed":27,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"id":"tQzU8HbBCi-8"},"outputs":[],"source":["class Linear_RNNBaseline(nn.Module):\n","    def __init__(self, hidden_dim, emb_dim, v_size):\n","        super().__init__()\n","        self.emb = nn.Embedding(len(TEXT.vocab), emb_dim)\n","        self.lstm = nn.LSTM(emb_dim, hidden_dim,)\n","        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_dim, 1)\n","\n","    def forward(self, seq):\n","        embedded = self.emb(seq)\n","        self.lstm.flatten_parameters()\n","        h, (h_T,c_T) = self.lstm(embedded)\n","        out = self.relu(self.fc1(h[-1,:,:]))\n","        preds = self.fc2(out)     \n","        return preds.squeeze()"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"status":"ok","timestamp":1658129868695,"user_tz":-240,"elapsed":23,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b02d052f-7436-4324-fb61-2de00b634d03","id":"qOiDrXO-Ci_Z"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear_RNNBaseline(\n","  (emb): Embedding(202243, 200)\n","  (lstm): LSTM(200, 300)\n","  (fc1): Linear(in_features=300, out_features=300, bias=True)\n","  (relu): ReLU()\n","  (fc2): Linear(in_features=300, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":40}],"source":["em_sz = 200\n","nh = 300\n","v_size = len(TEXT.vocab)\n","model = Linear_RNNBaseline(nh, em_sz, v_size)\n","model"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"status":"ok","timestamp":1658129868696,"user_tz":-240,"elapsed":15,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"id":"qJmAzKQfCi_a"},"outputs":[],"source":["model.to(device)\n","opt = optim.Adam(model.parameters(), lr=1e-3)\n","loss_func = nn.BCEWithLogitsLoss()\n","epochs = 7"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658129970698,"user_tz":-240,"elapsed":102016,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"outputId":"91e1952e-8b27-42a4-e0c0-dc50fc22c3a3","id":"-bNFUjJnCi_b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 0.010596711349487305, Validation Loss: 0.010025778738657634\n","Epoch: 2, Training Loss: 0.00858217374256679, Validation Loss: 0.010542406249046326\n","Epoch: 3, Training Loss: 0.006011102536746434, Validation Loss: 0.0062458453754583995\n","Epoch: 4, Training Loss: 0.002986657354448523, Validation Loss: 0.006183778937657674\n","Epoch: 5, Training Loss: 0.0014931640330169882, Validation Loss: 0.007623286259174347\n","Epoch: 6, Training Loss: 0.0005439712834211864, Validation Loss: 0.00921579901476701\n","Epoch: 7, Training Loss: 0.00018987881846925509, Validation Loss: 0.01112571081543962\n","CPU times: user 1min 37s, sys: 3.56 s, total: 1min 41s\n","Wall time: 1min 41s\n"]}],"source":["%%time\n","for epoch in range(1, epochs + 1):\n","    running_loss = 0.0\n","    running_corrects = 0\n","    model.train() \n","    for cnt, batch in enumerate(train_iter): \n","        x = batch.text\n","        y = batch.label.type(torch.float)\n","        opt.zero_grad()\n","        preds = model(x)\n","        loss = loss_func(preds, y)\n","        loss.backward()\n","        opt.step()\n","        running_loss += loss.item()\n","    epoch_loss = running_loss / len(trn)\n","    \n","    val_loss = 0.0\n","    model.eval()\n","    for batch in val_iter:\n","        x = batch.text\n","        y = batch.label.type(torch.float)\n","        preds = model(x)\n","        loss = loss_func(preds, y)\n","        val_loss += loss.item()\n","\n","    val_loss /= len(vld)\n","    print(f'Epoch: {epoch}, Training Loss: {epoch_loss}, Validation Loss: {val_loss}')"]},{"cell_type":"code","source":["print_metric(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658129976313,"user_tz":-240,"elapsed":5626,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}},"outputId":"2291587d-811a-46cb-8a35-ef6605e0bdc5","id":"q2I3O1DjCi_c"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n","  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.84\n","Precision: 0.85\n","Recall: 0.83\n","F1: 0.84\n"]}]},{"cell_type":"code","source":["# Accuracy: 0.84\n","# Precision: 0.85\n","# Recall: 0.83\n","# F1: 0.84"],"metadata":{"id":"Xe8b68KJpx9A","executionInfo":{"status":"ok","timestamp":1658129976314,"user_tz":-240,"elapsed":33,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"XNGeVCWZnlTi","executionInfo":{"status":"ok","timestamp":1658129976314,"user_tz":-240,"elapsed":31,"user":{"displayName":"Сергей Ощепков","userId":"03441214959068953559"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["Я объявил все возможные random.seed и все равно итоговые метрики изменяются в рамках одной сессии колаба. Буду рад если подскажете, в чем причина, где я ошибаюсь."],"metadata":{"id":"wTwjYXz-vat4"}}],"metadata":{"colab":{"collapsed_sections":[],"name":"Практическия_реализация_NLP.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}